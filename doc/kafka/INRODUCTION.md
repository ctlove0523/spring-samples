# Kafka介绍
**Apache Kafka是一个** *分布式流平台*，**分布式流平台意味着什么呢？**

流平台的三个关键能力：
* 发布和订阅流记录，这和消息队列或企业级消息系统类似。
* 以容错的方式存储流记录。
* 流记录产生时可以进行处理

Kafka通常用于两大类应用：

* 构建可在系统或应用程序之间可靠获取数据的实时流数据管道。
* 构建转换或响应数据流的实时流应用程序。

为了理解Kafka如何做这些事情，让我们深入探讨Kafka的能力。

首先是一些基本概念：

* Kafka以集群的方式运行在一个或多个服务器上，服务器可以跨多个数据中心。
* Kafka分类存储记录，记录的分类称为主题。
* 每条记录包括一个键、一个值和一个时间戳。

Kafka有四组核心API:

* [Producer API]() 允许应用向Kafka的一个或多个主题发送记录。
* [Consumer API]()允许应用订阅一个或多个主题，并处理该主题产生的记录。
* [Streams API]()允许应用充当流处理器的角色，消费来自一个或多个主题的输入流，将输出结果输出到一个或多个主题。可以高效的将输入流转换为输出流。
* [Connector API]() 允许构建可重用的生产者和消费者，将Kafka主题和其他应用或数据系统连接在一起。例如，一个关系型数据库连接器可以捕获数据库每一个表的变更。

![image](https://github.com/ctlove0523/Kafka-document/blob/master/images/kafka-apis.png)

在Kafka中，客户端和服务器之间的通信是通过简单，高性能，语言无关的[TCP协议](https://kafka.apache.org/protocol.html)完成的。 此协议已版本化并保持与旧版本的向后兼容性。 Kafka提供Java客户端，但客户端有[多种语言版本](https://cwiki.apache.org/confluence/display/KAFKA/Clients)。

## 主题和日志
主题是发送数据的分类或源名称。Kafka中的主题支持多订阅者，一个主题可以有0、1或多个消费者订阅发送到该主题下的数据。对于每个主题，Kafka群集都维护一个如下所示的分区日志：
![iamge](https://github.com/ctlove0523/Kafka-document/blob/master/images/log_anatomy.png)


每个分区都是一个有序的，不可变的记录序列，记录不断附加到结构化的提交日志中。 分区的每个记录都分配了一个称为偏移量的顺序ID号，偏移量是分钟中记录的唯一标识。
在保留期内，已经发布的记录不管是否已经被消费，kakfa集群都将持久存储这些记录。例如，保留策略为两天（所有记录保存两天），记录发布后的两天内记录可以被消费，之后记录江贝删除并释放存储空间。Kafka的性能不受数据量大小的影响，因此使用kafka长时间存储数据不是问题。

实际上，每个消费者保存的唯一元数据是偏移量或消费者在日志中的位置。偏移量由消费者控制：通常，消费者在读取纪录时线性移动偏移量，但是，由于偏移量实际上是受消费者控制，因此消费者可以可以自己喜欢的顺序读取记录。例如，消费者可以将偏移量设置为一个旧的偏移量来重复处理已经处理过的记录或者跳过多个记录并从最新的记录开始消费。
这种功能组合使得Kafka的消费者非常“轻量”，消费者的加入或离开对Kafka集群或其他消费者影响甚微。例如，可以在不改变任何已经存在消费者的情况下使用Kafka的命令行工具来消费任意主题的数据。
日志中的分区有多种用途。首先，允许日志扩展到超出适合单个服务器的大小，每个独立的分区的大小必须适合存储该分区的服务器，但是一个主题可以有多个分区所以可以处理任意数量的数据。其次，分区更多的充当并行性的单位（读、写）。

## Distribution
## Geo-Replication
## Producers
## Consumers
## Multi-tenancy
## Guarantees
## Kafka as a Messaging System
## Kafka as a Storage System
## Kafka for Stream Processing
## Putting the Pieces Together
